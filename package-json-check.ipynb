{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import pip._vendor.requests as requests\n",
    "import os\n",
    "import pprint as pp\n",
    "\n",
    "def read_dependency_file(username, repository_name, file_path, github_key):\n",
    "    headers = {}\n",
    "    if github_key:\n",
    "        headers['Authorization'] = f\"token {github_key}\"\n",
    "        \n",
    "    url = f'https://api.github.com/repos/{username}/{repository_name}/contents/{file_path}'\n",
    "    r = requests.get(url, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    file_content = data['content']\n",
    "    file_content_encoding = data.get('encoding')\n",
    "    if file_content_encoding == 'base64':\n",
    "        file_content = base64.b64decode(file_content).decode()\n",
    "\n",
    "    return file_content\n",
    "\n",
    "def get_repo_names(username, github_key):\n",
    "\n",
    "    all_repo_names = []\n",
    "    page_number = 1\n",
    "    per_page = 5\n",
    "    pages_remaining = True\n",
    "    while_count = 0\n",
    "\n",
    "    headers = {}\n",
    "    if github_key:\n",
    "        headers['Authorization'] = f\"token {github_key}\"\n",
    "\n",
    "    # Make get request to fetch data of all repos and convert to JSON\n",
    "\n",
    "    while (pages_remaining):\n",
    "        \n",
    "        current_url = f'https://api.github.com/users/{username}/repos?page={page_number}&per_page={per_page}'\n",
    "        print('')\n",
    "        print(f\"while_count - {while_count}\")\n",
    "        r = requests.get(current_url, headers=headers)\n",
    "        r.raise_for_status()\n",
    "        # pp.pprint(r.headers)\n",
    "        data = r.json()\n",
    "\n",
    "        # Loop through data JSON object to extract all repo names\n",
    "\n",
    "        for i in range(0, len(data)):   \n",
    "            all_repo_names.append(data[i]['name'])\n",
    "        print(all_repo_names)\n",
    "\n",
    "        nextPattern = \"rel=\\\"next\\\"\"\n",
    "        link = r.headers.get('link')\n",
    "        # print(link)\n",
    "\n",
    "        if nextPattern in link:\n",
    "            print('Found next pattern in link, continue to next page')\n",
    "            page_number += 1\n",
    "            while_count += 1\n",
    "            print(current_url)\n",
    "        else:\n",
    "            print(\"Can't find next pattern, must be last page\")\n",
    "            pages_remaining = False\n",
    "\n",
    "    pp.pprint(all_repo_names)\n",
    "    return all_repo_names\n",
    "\n",
    "def extract_repo_dependencies(all_repo_names, repos_directory, dependency_files, username, github_key):\n",
    "\n",
    "    for i in range(0,len(all_repo_names)):\n",
    "\n",
    "        # Create make filepath to create new repo folders:\n",
    "        path = os.path.join(repos_directory, all_repo_names[i])\n",
    "\n",
    "        # Create repo folders\n",
    "        os.mkdir(path)\n",
    "\n",
    "        # Create dependency files within repo folders \n",
    "        for j in range(0, len(dependency_files)):\n",
    "            try:\n",
    "                file_content = read_dependency_file(username, all_repo_names[i], dependency_files[j], github_key)\n",
    "                f = open(f'{repos_directory}/{all_repo_names[i]}/{dependency_files[j]}', \"w\")\n",
    "                f.write(file_content)\n",
    "                f.close()\n",
    "                print(f'{dependency_files[j]} file created.')\n",
    "            except: \n",
    "                print('Could not find package.json or package-lock.json')\n",
    "\n",
    "def main():\n",
    "    GITHUB_KEY = os.environ['GITHUB_KEY']\n",
    "    USERNAME = 'Harrisman05'\n",
    "    DEPENDENCY_FILES = ['pom.xml','package.json','package-lock.json','requirements.txt']\n",
    "    REPOS_DIRECTORY = 'repos'\n",
    "\n",
    "    ALL_REPO_NAMES = get_repo_names(USERNAME, GITHUB_KEY)\n",
    "    extract_repo_dependencies(ALL_REPO_NAMES, REPOS_DIRECTORY, DEPENDENCY_FILES, USERNAME, GITHUB_KEY)\n",
    "\n",
    "    print(len(ALL_REPO_NAMES))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dependency_checker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bb2c615e6571d5756fb47ecc774e74876f593876d64f7be0c48842ff5d06f09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
